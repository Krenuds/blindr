# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview
The user is that you tutor them as they learn about AI models and MCP. Please take it slow. This should be a learning experience for them.


**CRITICAL RULES**
- Always begin sessions by reading the latest 3 commits in git_logs.md
- Read Requirements.txt
- Always consult online documentation for each module while planning. 
- Test all code after finishing each task before moving on by reading the service logs.
- Git commit with comment after successfully completing tasks.  
- All models are running locally. Either via docker or as system services.

**PROJECT OVERVIEW** 
```
graph TB
    %% User Layer
    subgraph "User Layer"
        User[("ğŸ‘¤ Discord User")]
    end

    %% Discord Layer
    subgraph "Discord Platform"
        DiscordServer["ğŸ® Discord Server<br/>Voice Channel"]
    end

    %% Bot Layer
    subgraph "Bot Service"
        Bot["ğŸ¤– Discord Bot<br/>Python 3.12+<br/>py-cord<br/>AudioSink Voice Recording"]
    end

    %% API Gateway Layer
    subgraph "API Gateway"
        API["ğŸŒ FastAPI<br/>Port: 8000"]
    end

    %% Speech Processing Layer
    subgraph "Speech Processing"
        Whisper["ğŸ¤ Whisper STT<br/>Native Service<br/>Port: 9000"]
        Piper["ğŸ”Š Piper TTS<br/>Docker Container<br/>Port: 10200"]
    end

    %% Intelligence Layer
    subgraph "Intelligence & Routing"
        Classifier["ğŸ§  DistilBERT<br/>Intent Classifier<br/>Port: 8001"]
        LiteLLM["ğŸ”€ LiteLLM Router<br/>Proxy Server<br/>Port: 4000"]
    end

    %% Model Layer
    subgraph "Model Hosting"
        Ollama["ğŸ’¾ Ollama<br/>Model Host<br/>Port: 11434"]
        Llama["ğŸ’¬ Llama 3.2<br/>3B Model<br/>Conversational"]
        Qwen["âš™ï¸ Qwen 2.5-Coder<br/>7B Model<br/>Coding/Tools"]
    end

    %% Optional Storage
    subgraph "Cache Layer"
        Redis[("ğŸ—„ï¸ Redis<br/>Cache/Sessions<br/>Port: 6379")]
    end

    %% User Voice Flow
    User -->|"ğŸ¤ Voice Input"| DiscordServer
    DiscordServer -->|"ğŸ“¡ Opus Packets<br/>48kHz"| Bot
    
    %% Audio Processing
    Bot -->|"ğŸ”„ Decode Opus â†’ PCM<br/>16-bit 48kHz"| API
    API -->|"ğŸµ PCM/WAV Audio"| Whisper
    Whisper -->|"ğŸ“ Transcribed Text"| API

    %% Intelligence Routing
    API -->|"â“ User Query"| Classifier
    Classifier -->|"ğŸ·ï¸ Intent Classification<br/>(conversational/agentic)"| API
    API -->|"ğŸ“¨ Routed Request"| LiteLLM
    
    %% Model Selection
    LiteLLM -->|"ğŸš¦ Route Decision"| Ollama
    Ollama -->|"ğŸ’­ Conversational Route"| Llama
    Ollama -->|"ğŸ› ï¸ Agentic Route"| Qwen
    
    %% Response Generation
    Llama -->|"ğŸ’¬ Response Text"| Ollama
    Qwen -->|"ğŸ“‹ Response Text"| Ollama
    Ollama -->|"âœ¨ Generated Text"| LiteLLM
    LiteLLM -->|"ğŸ“¤ Response"| API

    %% Text-to-Speech
    API -->|"ğŸ“„ Response Text"| Piper
    Piper -->|"ğŸ¶ Audio Stream<br/>WAV/PCM"| API
    
    %% Voice Output
    API -->|"ğŸ”‰ Audio Data"| Bot
    Bot -->|"ğŸ”Š Voice Output"| DiscordServer
    DiscordServer -->|"ğŸ§ Audio Stream"| User

    %% Cache Integration
    API -.->|"ğŸ” Cache Check"| Redis
    Redis -.->|"ğŸ’¾ Cached Data"| API    
```

